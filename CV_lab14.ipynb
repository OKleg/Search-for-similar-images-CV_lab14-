{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4n66P7A3OJa3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import ast\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxMJ-pFuOpKe"
      },
      "source": [
        "###### Выгрузка гугл диска в GoogleColab (1 раз)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3sPiiRJOnAp"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvVMsNOGOtLW"
      },
      "source": [
        "# *CLIP*\n",
        "###### Данная модель заменяет собой реализацию кодирования изображения в вектор из предыдущей лабораторной работы (а именно связку SIFT + K-Means + Histogram).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCE415AzOsOL"
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG9rOKYyO1ZS"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, transform = clip.load('ViT-B/32', device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZscYzGEO2Av"
      },
      "outputs": [],
      "source": [
        "def image_to_vector(image, model):\n",
        "    # Convert image\n",
        "    image = Image.fromarray(image)\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Encode using CLIP\n",
        "    with torch.no_grad():\n",
        "        image_features = model.encode_image(image)\n",
        "\n",
        "    # Normalize\n",
        "    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    return image_features.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 5\n",
        "#### Create indexed DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create pd.DataFrame for all images in path\n",
        "def create_database(path, model):\n",
        "    data = []\n",
        "    for index, filename in enumerate(os.listdir(path)):\n",
        "        img = cv2.imread(os.path.join(path, filename))\n",
        "        if img is not None:\n",
        "            vector = image_to_vector(img, model)\n",
        "            if vector is not None:\n",
        "                data.append({'index': index, 'path': os.path.join(path, filename), 'vector': vector.tolist()[0]})\n",
        "    df = pd.DataFrame(data)\n",
        "    return df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
